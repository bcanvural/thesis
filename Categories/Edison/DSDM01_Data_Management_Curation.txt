Data curation is a term used to indicate management activities related to organization and integration of data collected from various sources, annotation of the data, and publication and presentation of the data such that the value of the data is maintained over time, and the data remains available for reuse and preservation. Data curation includes "all the processes needed for principled and controlled data creation, maintenance, and management, together with the capacity to add value to data".[1] In science, data curation may indicate the process of extraction of important information from scientific texts, such as research articles by experts, to be converted into an electronic format, such as an entry of a biological database.[2] The term is also used in the humanities, where increasing cultural and scholarly data from digital humanities projects requires the expertise and analytical practices of data curation.[3] In broad terms, curation means a range of activities and processes done to create, manage, maintain, and validate a component.[4]

Contents

    1 Definition and practice
    2 Projects and studies
    3 See also
    4 References
    5 External links

Definition and practice

According to the University of Illinois' Graduate School of Library and Information Science, "Data curation is the active and on-going management of data through its lifecycle of interest and usefulness to scholarship, science, and education; curation activities enable data discovery and retrieval, maintain quality, add value, and provide for re-use over time."[5]

Deep background on data libraries appeared in a 1982 issue of the Illinois journal, Library Trends.[6] For historical background on the data archive movement, see "Social Scientific Information Needs for Numeric Data: The Evolution of the International Data Archive Infrastructure."[7]

This term is sometimes used in context of biological databases, where specific biological information is firstly obtained from a range of research articles and then stored within a specific category of database. For instance, information about anti-depressant drugs can be obtained from various sources and, after checking whether they are available as a database or not, they are saved under a drug's database's anti-depressive category. Enterprises are also utilizing data curation within their operational and strategic processes to ensure data quality and accuracy.[8]
Projects and studies

The Dissemination Information Packages (DIPS) for Information Reuse (DIPIR) project is studying research data produced and used by quantitative social scientists, archaeologists, and zoologists. The intended audience is researchers who use secondary data and the digital curators, digital repository managers, data center staff, and others who collect, manage, and store digital information.[9]
See also

    Biocurator
    Data archaeology
    Data degradation
    Data format management
    Data governance
    Data management
    Data stewardship
    Data wrangling, low-level activities to parse and reformat data
    Informationist, an individual with extensive industry expertise, acute familiarity with organizational structures and processes, deep domain level information mastery and information systems technical savvy






Data management comprises all the disciplines related to managing data as a valuable resource.

Contents

    1 Overview
    2 Corporate Data Quality Management
    3 Topics in Data Management
    4 Body of Knowledge
    5 Usage
    6 Integrated data management
    7 See also
    8 References
    9 External links

Overview

The official definition provided by DAMA International, the professional organization for those in the data management profession, is: "Data Resource Management is the development and execution of architectures, policies, practices and procedures that properly manage the full data lifecycle needs of an enterprise." This definition is fairly broad and encompasses a number of professions which may not have direct technical contact with lower-level aspects of data management, such as relational database management.
The data lifecycle

Alternatively, the definition provided in the DAMA Data Management Body of Knowledge ([1]) is: "Data management is the development, execution and supervision of plans, policies, programs and practices that control, protect, deliver and enhance the value of data and information assets."[2]

The concept of "Data Management" arose in the 1980s as technology moved from sequential processing (first cards, then tape) to random access processing. Since it was now technically possible to store a single fact in a single place and access that using random access disk, those suggesting that "Data Management" was more important than "Process Management" used arguments such as "a customer's home address is stored in 75 (or some other large number) places in our computer systems." During this period, random access processing was not competitively fast, so those suggesting "Process Management" was more important than "Data Management" used batch processing time as their primary argument. As applications moved into real-time, interactive applications, it became obvious to most practitioners that both management processes were important. If the data was not well defined, the data would be mis-used in applications. If the process wasn't well defined, it was impossible to meet user needs.
Corporate Data Quality Management

Corporate Data Quality Management (CDQM) is, according to the European Foundation for Quality Management and the Competence Center Corporate Data Quality (CC CDQ, University of St. Gallen), the whole set of activities intended to improve corporate data quality (both reactive and preventive). Main premise of CDQM is the business relevance of high-quality corporate data. CDQM comprises with following activity areas:.[3]

    Strategy for Corporate Data Quality: As CDQM is affected by various business drivers and requires involvement of multiple divisions in an organization; it must be considered a company-wide endeavor.
    Corporate Data Quality Controlling: Effective CDQM requires compliance with standards, policies, and procedures. Compliance is monitored according to previously defined metrics and performance indicators and reported to stakeholders.
    Corporate Data Quality Organization: CDQM requires clear roles and responsibilities for the use of corporate data. The CDQM organization defines tasks and privileges for decision making for CDQM.
    Corporate Data Quality Processes and Methods: In order to handle corporate data properly and in a standardized way across the entire organization and to ensure corporate data quality, standard procedures and guidelines must be embedded in companyâ€™s daily processes.
    Data Architecture for Corporate Data Quality: The data architecture consists of the data object model - which comprises the unambiguous definition and the conceptual model of corporate data - and the data storage and distribution architecture.
    Applications for Corporate Data Quality: Software applications support the activities of Corporate Data Quality Management. Their use must be planned, monitored, managed and continuously improved.

Topics in Data Management

Topics in Data Management, grouped by the DAMA DMBOK Framework,[4] include:

    Data governance
        Data asset
        Data governance
        Data steward
    Data Architecture, Analysis and Design
        Data analysis
        Data architecture
        Data modeling
    Database Management
        Data maintenance
        Database administration
        Database management system
    Data Security Management
        Data access
        Data erasure
        Data privacy
        Data security
    Data Quality Management
        Data cleansing
        Data integrity
        Data enrichment
        Data quality
        Data quality assurance
    Reference and Master Data Management
        Data integration
        Master data management
        Reference data
    Data Warehousing and Business Intelligence Management
        Business intelligence
        Data mart
        Data mining
        Data movement (Extract, transform, load )
        Data warehouse
    Document, Record and Content Management
        Document management system
        Records management
    Meta Data Management
        Meta-data management
        Metadata
        Metadata discovery
        Metadata publishing
        Metadata registry
    Contact Data Management
        Business continuity planning
        Marketing operations
        Customer data integration
        Identity management
        Identity theft
        Data theft
        ERP software
        CRM software
        Address (geography)
        Postal code
        Email address
        Telephone number

Body of Knowledge

The DAMA Guide to the Data Management Body of Knowledge" (DAMA-DMBOK Guide), under the guidance of a new DAMA-DMBOK Editorial Board. This publication is available from April 5, 2009.
Usage

In modern management usage, one can easily discern a trend away from the term "data" in composite expressions to the term "information" or even "knowledge" when talking in a non-technical context. Thus there exists not only data management, but also information management and knowledge management. This is a misleading trend as it obscures that traditional data are managed or somehow processed on second looks.[citation needed] The distinction between data and derived values can be seen in the information ladder.[citation needed] While data can exist as such, "information" and "knowledge" are always in the "eye" (or rather the brain) of the beholder and can only be measured in relative units.

Several organisations have established a data management centre (DMC)[5] for their operations.
Integrated data management

Integrated data management (IDM) is a tools approach to facilitate data management and improve performance. IDM consists of an integrated, modular environment to manage enterprise application data, and optimize data-driven applications over its lifetime.[6][7][8][9] IDM's purpose is to:

    Produce enterprise-ready applications faster
    Improve data access, speed iterative testing
    Empower collaboration between architects, developers and DBAs
    Consistently achieve service level targets
    Automate and simplify operations
    Provide contextual intelligence across the solution stack
    Support business growth
    Accommodate new initiatives without expanding infrastructure
    Simplify application upgrades, consolidation and retirement
    Facilitate alignment, consistency and governance
    Define business policies and standards up front; share, extend, and apply throughout the lifecycle




